{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761071f0",
   "metadata": {},
   "source": [
    "email agent\n",
    "- authenticates user\n",
    "    - only then are they allowed into the \"inbox\"\n",
    "    - dynamic tools and prompt on the condition of there being an email and password in state that match hardcoded\n",
    "- checks \"inbox\"\n",
    "    - email in tool\n",
    "- sends emails\n",
    "    - human in the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78765ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430fd535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class EmailContext:\n",
    "    email_address: str = \"julie@example.com\"\n",
    "    password: str = \"password123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b39938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentState\n",
    "\n",
    "class AuthenticatedState(AgentState):\n",
    "    authenticated: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d7cf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.types import Command\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "@tool\n",
    "def check_inbox() -> str:\n",
    "    \"\"\"Check the inbox for recent emails\"\"\"\n",
    "    return \"\"\"\n",
    "    Hi Julie, \n",
    "    I'm going to be in town next week and was wondering if we could grab a coffee?\n",
    "    - best, Jane (jane@example.com)\n",
    "    \"\"\"\n",
    "\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Send an response email\"\"\"\n",
    "    return f\"Email sent to {to} with subject {subject} and body {body}\"\n",
    "\n",
    "@tool\n",
    "def authenticate(email: str, password: str, runtime: ToolRuntime) -> Command:\n",
    "    \"\"\"Authenticate the user with the given email and password\"\"\"\n",
    "    if email == runtime.context.email_address and password == runtime.context.password:\n",
    "        return Command(update={\n",
    "            \"authenticated\": True, \n",
    "            \"messages\": [ToolMessage(\n",
    "                \"Successfully authenticated\", \n",
    "                tool_call_id=runtime.tool_call_id)]\n",
    "        })\n",
    "    else:\n",
    "        return Command(update={\n",
    "            \"authenticated\": False,\n",
    "            \"messages\": [ToolMessage(\n",
    "                \"Authentication failed\", \n",
    "                tool_call_id=runtime.tool_call_id)]\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9493f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "from typing import Callable\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_tool_call(request: ModelRequest, \n",
    "handler: Callable[[ModelRequest], ModelResponse]) -> ModelResponse:\n",
    "\n",
    "    \"\"\"Allow read inbox and send email tools only if user provides correct email and password\"\"\"\n",
    "\n",
    "    authenticated = request.state.get(\"authenticated\")\n",
    "    \n",
    "    if authenticated:\n",
    "        tools = [check_inbox, send_email]\n",
    "    else:\n",
    "        tools = [authenticate]\n",
    "\n",
    "    request = request.override(tools=tools) \n",
    "    return handler(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eee1076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import dynamic_prompt\n",
    "\n",
    "authenticated_prompt = \"You are a helpful assistant that can check the inbox and send emails.\"\n",
    "unauthenticated_prompt = \"You are a helpful assistant that can authenticate users.\"\n",
    "\n",
    "@dynamic_prompt\n",
    "def dynamic_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Generate system prompt based on authentication status\"\"\"\n",
    "    authenticated = request.state.get(\"authenticated\")\n",
    "\n",
    "    if authenticated:\n",
    "        return authenticated_prompt\n",
    "    else:\n",
    "        return unauthenticated_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3828133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    \"gpt-5-nano\",\n",
    "    tools=[authenticate, check_inbox, send_email],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    state_schema=AuthenticatedState,\n",
    "    context_schema=EmailContext,\n",
    "    middleware=[\n",
    "        dynamic_tool_call, \n",
    "        dynamic_prompt,\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"authenticate\": False,\n",
    "                \"check_inbox\": False,\n",
    "                \"send_email\": True,\n",
    "            })\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd702b4-7ad0-4489-88b3-bd99b021827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\n",
    "            {\"messages\": [HumanMessage(content=\"Please check my inbox.\")]},\n",
    "            context = EmailContext(),\n",
    "            config = config\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ef905b5-4118-4c98-8e19-c103a65afeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suvo/Documents/Langchain/lca-lc-foundations/.venv/lib/python3.12/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='context', input_value=EmailContext(email_addres... password='password123'), input_type=EmailContext])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 1 new email from Jane (jane@example.com): “Hi Julie, I’m going to be in town next week and was wondering if we could grab a coffee?”\n",
      "\n",
      "Would you like me to draft and send a reply? I can tailor a few quick options. Here are some templates you can choose from or we can customize:\n",
      "\n",
      "Option 1 — Casual and upbeat\n",
      "Hi Jane,\n",
      "Coffee sounds great! I’m around next week. How about [time] on [day] at [cafe]? If that doesn’t work, tell me what times you have in mind.\n",
      "Cheers,\n",
      "Julie\n",
      "\n",
      "Option 2 — Short and flexible\n",
      "Hi Jane, I’d love to. I’m available [times]. Which works for you?\n",
      "\n",
      "Option 3 — If you want a specific location\n",
      "Hi Jane, I’d love to catch up. How about [cafe/area] next week? I’m free [days/times]. Let me know what works.\n",
      "\n",
      "Tips:\n",
      "- Replace [day/time/cafe] with your actual availability and a nearby cafe.\n",
      "- If you prefer a firm plan, propose a couple of exact slots.\n",
      "\n",
      "Would you like me to send one of these now? If you share your availability and preferred cafe, I’ll draft a final version and send it. I can also set a reminder or add a calendar invite after you confirm.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "            {\"messages\": [HumanMessage(content=\"julie@example.com, password123\")]},\n",
    "            context = EmailContext(),\n",
    "            config = config\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54b6429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft 1 – Reply to Jane’s coffee invitation (casual and upbeat)\n",
      "\n",
      "Subject: Re: Coffee next week\n",
      "\n",
      "Hi Jane,\n",
      "\n",
      "Coffee sounds great! I’m around next week. How about [time] on [day] at [cafe]? If that doesn’t work, tell me what times you have in mind.\n",
      "\n",
      "Cheers,\n",
      "Julie\n",
      "\n",
      "Notes:\n",
      "- Replace [time], [day], and [cafe] with your actual availability.\n",
      "- If you’d prefer a firmer plan, propose a couple of exact slots.\n",
      "\n",
      "Would you like me to customize this with your preferred times and a specific cafe, and send it? I can also add a calendar invite after you confirm.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"draft 1\")]},\n",
    "    context=EmailContext(),\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8f92733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(response['__interrupt__'][0].value['action_requests'][0]['args']['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "707f521a-30e1-4979-ba1a-b448188c2809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draft 1 – Reply to Jane’s coffee invitation (casual and upbeat)\n",
      "\n",
      "Subject: Re: Coffee next week\n",
      "\n",
      "Hi Jane,\n",
      "\n",
      "Coffee sounds great! I’m around next week. How about [time] on [day] at [cafe]? If that doesn’t work, tell me what times you have in mind.\n",
      "\n",
      "Cheers,\n",
      "Julie\n",
      "\n",
      "Notes:\n",
      "- Replace [time], [day], and [cafe] with your actual availability.\n",
      "- If you’d prefer a firmer plan, propose a couple of exact slots.\n",
      "\n",
      "Would you like me to customize this with your preferred times and a specific cafe, and send it? I can also add a calendar invite after you confirm.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = agent.invoke(\n",
    "    Command( \n",
    "        resume={\"decisions\": [{\"type\": \"draft 1\"}]}  # or \"reject\"\n",
    "    ), \n",
    "    config=config # Same thread ID to resume the paused conversation\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c479ab7c-0287-43fc-ba58-47b112c8a91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Re: Coffee next week\n",
      "\n",
      "Hi Jane,\n",
      "\n",
      "Coffee sounds great! I’m around next week. How about 10:00 AM on Tuesday at Cannelle? If that doesn’t work, tell me what times you have in mind.\n",
      "\n",
      "Cheers,\n",
      "Julie\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Use 10am Tuesday at Cannelle (or suggest a cafe). Update the draft and show me the final email only.\")]},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7d6aae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Re: Coffee next week\n",
      "\n",
      "Hi Jane,\n",
      "\n",
      "Coffee sounds great! I’m around next week. How about 10:00 AM on Tuesday at Cannelle? If that doesn’t work, tell me what times you have in mind.\n",
      "\n",
      "Cheers,\n",
      "Julie\n"
     ]
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "response = agent.invoke(\n",
    "    Command( \n",
    "        resume={\"decisions\": [{\"type\": \"approve\"}]}  # or \"reject\"\n",
    "    ), \n",
    "    config=config # Same thread ID to resume the paused conversation\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a87b96f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'authenticated': True,\n",
      " 'messages': [HumanMessage(content='draft 1', additional_kwargs={}, response_metadata={}, id='e0680448-4bac-4dd3-9cda-325ac333b3df'),\n",
      "              AIMessage(content='I’m happy to help with Draft 1. Could you share a bit more about what you’re drafting? Specifically:\\n- Type: email, letter, report, proposal, blog post, etc.\\n- Topic or purpose\\n- Audience\\n- Tone (formal, friendly, persuasive, etc.)\\n- Length or word count\\n- Any key points or must-have details\\n- Deadline or anything else I should know\\n\\nIf you’d like, I can also provide a ready-to-edit generic Draft 1 now. Here’s a simple, adaptable template you can customize:\\n\\nDraft 1 – Professional update (email or memo)\\nSubject: [Project/Topic] – Draft 1\\n\\nHi [Name/Team],\\n\\nI’m sharing an initial draft of [Project/Topic] to gather your input. Here’s where things stand:\\n\\n- Objective: [Brief objective]\\n- Current status: [What’s done, what’s in progress]\\n- Key milestones completed: [List]\\n- Upcoming milestones: [List with dates]\\n- Risks and mitigations: [Brief bullets]\\n- Decisions needed: [What you need from the recipient]\\n- Next steps: [Actions and owners]\\n\\nAttachments: [if any]\\n\\nPlease let me know your thoughts by [date], or feel free to propose any changes directly in this draft. I can incorporate feedback and share a revised version as Draft 2.\\n\\nBest regards,\\n[Your Name]\\n[Title]\\n[Company]\\n[Contact]\\n\\nIf you want a different format (e.g., a cover letter, a blog intro, a slide outline), tell me the type and details and I’ll tailor Draft 1 for you.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1235, 'prompt_tokens': 147, 'total_tokens': 1382, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CqeXVDyFrah0w2WnpL21T39tZAblW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b556f-6c87-7411-a6cb-845fc15993af-0', usage_metadata={'input_tokens': 147, 'output_tokens': 1235, 'total_tokens': 1382, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}}),\n",
      "              HumanMessage(content='draft 1', additional_kwargs={}, response_metadata={}, id='a968156f-740e-4a23-a74b-a22eff35861d'),\n",
      "              AIMessage(content='Here’s a ready-to-edit Draft 1 you can use as a professional update email. If you want a different format, tell me the type and details and I’ll tailor it.\\n\\nDraft 1 – Project update (email)\\n\\nSubject: [Project/Topic] – Draft 1\\n\\nHi [Name/Team],\\n\\nI’m sharing an initial draft of [Project/Topic] to gather input. Here’s where things stand:\\n\\n- Objective: [Brief objective]\\n- Current status: [What’s done, what’s in progress]\\n- Key milestones completed: [List]\\n- Upcoming milestones: [List with dates]\\n- Risks and mitigations: [Brief bullets]\\n- Decisions needed: [What you need from the recipient]\\n- Next steps: [Actions and owners]\\n\\nAttachments: [if any]\\n\\nPlease let me know your thoughts by [date], or feel free to propose changes directly in this draft. I can incorporate feedback and share a revised version as Draft 2.\\n\\nBest regards,\\n[Your Name]\\n[Title]\\n[Company]\\n[Contact]\\n\\nIf you’d prefer a different format (e.g., cover letter, blog intro, slide outline), just tell me the type and details and I’ll tailor Draft 1 accordingly.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1665, 'prompt_tokens': 490, 'total_tokens': 2155, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1408, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CqecorxpDDpUPMAhbLw6CNDWTE3tL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5574-75c0-7c91-9e59-005fee3fbca2-0', usage_metadata={'input_tokens': 490, 'output_tokens': 1665, 'total_tokens': 2155, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1408}}),\n",
      "              HumanMessage(content='Please check my inbox.', additional_kwargs={}, response_metadata={}, id='7309300e-7650-46c3-a0d6-1ad362b30500'),\n",
      "              AIMessage(content='I can’t access or check your inbox directly. But I can help you do it quickly or draft responses. Here are a few quick options:\\n\\nOption 1: Quick self-check guide (popular email providers)\\n- Gmail:\\n  - Open Inbox, switch to Unread.\\n  - Use search: is:unread newer_than:1d or from:sender@example.com or subject:deadline.\\n  - Check Primary, then Updates/Promotions if you use labels.\\n  - Star or label urgent items.\\n\\n- Outlook:\\n  - Open Inbox, view Unread.\\n  - Use Search: isread:no OR received:today.\\n  - Use Focused vs Other if enabled; set Rules to auto-categorize.\\n\\n- Apple Mail:\\n  - Open Inbox, use Unread smart mailbox.\\n  - Use search filters (from:, subject:, date:).\\n\\nOption 2: Triage workflow (35–60 seconds)\\n- Step 1: Unread + today’s messages → decide action (reply, delegate, file).\\n- Step 2: Flag/label urgent items (deadline, follow-up).\\n- Step 3: Move non-urgent to a “Later” folder.\\n- Step 4: Draft quick replies for common requests.\\n\\nOption 3: Get help drafting replies\\n- Paste the email content (or summarize it) and what you want to say, and I’ll draft replies or follow-up messages.\\n\\nOption 4: Automation ideas\\n- Create a rule/label for “Action Needed” and auto-flag urgent emails.\\n- Set a daily 5-minute inbox check window and a “to-do” list after review.\\n\\nIf you tell me which email service you’re using and what you’re specifically looking for (urgent messages, action items, follow-ups, etc.), I’ll tailor steps or draft templates for you. If you’d like, you can also paste any emails here (redacting sensitive info), and I’ll help craft responses.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1366, 'prompt_tokens': 753, 'total_tokens': 2119, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 960, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cqeifudq93tbIWEV4bESNACb9xjcZ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5579-fc4c-76e1-8cd0-824a6eac385f-0', usage_metadata={'input_tokens': 753, 'output_tokens': 1366, 'total_tokens': 2119, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 960}}),\n",
      "              HumanMessage(content='julie@example.com, password123', additional_kwargs={}, response_metadata={}, id='5e4e20a3-e9a2-454a-9d2a-dca095f6cb03'),\n",
      "              AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 286, 'prompt_tokens': 1167, 'total_tokens': 1453, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cqelt7mikQiCma5bP76bazeoFDWgw', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b557d-0b6b-7341-a388-8e3ffc1f9c8c-0', tool_calls=[{'name': 'authenticate', 'args': {'email': 'julie@example.com', 'password': 'password123'}, 'id': 'call_XQ1pYRiHz32gSzwnAolFgs14', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1167, 'output_tokens': 286, 'total_tokens': 1453, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}}),\n",
      "              ToolMessage(content='Successfully authenticated', name='authenticate', id='6ae8bad4-3302-47da-b207-b46718f0375e', tool_call_id='call_XQ1pYRiHz32gSzwnAolFgs14'),\n",
      "              AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 340, 'prompt_tokens': 1223, 'total_tokens': 1563, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CqelwJZXtLXFsEymw9OG2DGbUHiM1', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b557d-1924-7e21-a8ba-2a7f80c76cab-0', tool_calls=[{'name': 'check_inbox', 'args': {}, 'id': 'call_z8jVjyY7akGNFtfrAV90jZvn', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1223, 'output_tokens': 340, 'total_tokens': 1563, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}}),\n",
      "              ToolMessage(content=\"\\n    Hi Julie, \\n    I'm going to be in town next week and was wondering if we could grab a coffee?\\n    - best, Jane (jane@example.com)\\n    \", name='check_inbox', id='0d006570-a6ee-4bfa-be8e-b04a08eb6f62', tool_call_id='call_z8jVjyY7akGNFtfrAV90jZvn'),\n",
      "              AIMessage(content='I found 1 new email from Jane (jane@example.com): “Hi Julie, I’m going to be in town next week and was wondering if we could grab a coffee?”\\n\\nWould you like me to draft and send a reply? I can tailor a few quick options. Here are some templates you can choose from or we can customize:\\n\\nOption 1 — Casual and upbeat\\nHi Jane,\\nCoffee sounds great! I’m around next week. How about [time] on [day] at [cafe]? If that doesn’t work, tell me what times you have in mind.\\nCheers,\\nJulie\\n\\nOption 2 — Short and flexible\\nHi Jane, I’d love to. I’m available [times]. Which works for you?\\n\\nOption 3 — If you want a specific location\\nHi Jane, I’d love to catch up. How about [cafe/area] next week? I’m free [days/times]. Let me know what works.\\n\\nTips:\\n- Replace [day/time/cafe] with your actual availability and a nearby cafe.\\n- If you prefer a firm plan, propose a couple of exact slots.\\n\\nWould you like me to send one of these now? If you share your availability and preferred cafe, I’ll draft a final version and send it. I can also set a reminder or add a calendar invite after you confirm.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1052, 'prompt_tokens': 1286, 'total_tokens': 2338, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 768, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cqem0W8Yu67nP0diy3gkjn2QxgOa3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b557d-291a-71e2-8066-2ac20b4c125c-0', usage_metadata={'input_tokens': 1286, 'output_tokens': 1052, 'total_tokens': 2338, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 768}}),\n",
      "              HumanMessage(content='draft 1', additional_kwargs={}, response_metadata={}, id='abe50bb0-c326-488a-9aac-7ca7e7c2fbb4'),\n",
      "              AIMessage(content='Draft 1 – Reply to Jane’s coffee invitation (casual and upbeat)\\n\\nSubject: Re: Coffee next week\\n\\nHi Jane,\\n\\nCoffee sounds great! I’m around next week. How about [time] on [day] at [cafe]? If that doesn’t work, tell me what times you have in mind.\\n\\nCheers,\\nJulie\\n\\nNotes:\\n- Replace [time], [day], and [cafe] with your actual availability.\\n- If you’d prefer a firmer plan, propose a couple of exact slots.\\n\\nWould you like me to customize this with your preferred times and a specific cafe, and send it? I can also add a calendar invite after you confirm.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 979, 'prompt_tokens': 1574, 'total_tokens': 2553, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 832, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CqemnHHg7tYU4gudy5jRQpMwThTa8', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b557d-e626-72d1-a973-796c027832f4-0', usage_metadata={'input_tokens': 1574, 'output_tokens': 979, 'total_tokens': 2553, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 832}}),\n",
      "              HumanMessage(content='Use 10am Tuesday at Cannelle (or suggest a cafe). Update the draft and show me the final email only.', additional_kwargs={}, response_metadata={}, id='96c012d3-d3d3-4ce7-88bc-210353bef273'),\n",
      "              AIMessage(content='Subject: Re: Coffee next week\\n\\nHi Jane,\\n\\nCoffee sounds great! I’m around next week. How about 10:00 AM on Tuesday at Cannelle? If that doesn’t work, tell me what times you have in mind.\\n\\nCheers,\\nJulie', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 573, 'prompt_tokens': 1747, 'total_tokens': 2320, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1024}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cqet9wAmLnSXwr4xyMgCTIGrnFeeW', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5583-e76f-7e71-bda9-427d8def2c93-0', usage_metadata={'input_tokens': 1747, 'output_tokens': 573, 'total_tokens': 2320, 'input_token_details': {'audio': 0, 'cache_read': 1024}, 'output_token_details': {'audio': 0, 'reasoning': 512}})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5204bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
